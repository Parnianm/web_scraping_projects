{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time   # Import time module for delays\n",
    "import json   # Import JSON module for handling cookies\n",
    "import random  # Import random module to select user agents\n",
    "import asyncio  # Import asyncio for async execution\n",
    "import nest_asyncio  # Import nest_asyncio to allow nested async loops\n",
    "from selenium import webdriver  # Import Selenium WebDriver\n",
    "from selenium.webdriver.common.by import By  # Import By class for locating elements\n",
    "from selenium.webdriver.chrome.service import Service  # Import Service for ChromeDriver\n",
    "from selenium.webdriver.chrome.options import Options  # Import Options to configure WebDriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait   # Import WebDriverWait for explicit waits\n",
    "from selenium.webdriver.support import expected_conditions as EC  # Import expected_conditions for conditions\n",
    "import pandas as pd  # Import pandas for handling and saving extracted data\n",
    "# Importing urlparse and parse_qs from urllib.parse to parse URLs and extract query parameters\n",
    "from urllib.parse import urlparse, parse_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üü° Helper Function: Setup WebDriver\n",
    "# ============================\n",
    "def setup_driver():\n",
    "    \"\"\"\n",
    "    Initializes and configures Selenium WebDriver with performance optimizations.\n",
    "    \"\"\"\n",
    "    user_agents = [  # List of user agents to avoid detection\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)\",\n",
    "        \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:94.0)\",\n",
    "    ]\n",
    "    \n",
    "    chrome_options = Options()  # Create Chrome options object\n",
    "     # Running in headless mode for efficiency (Uncomment if needed)\n",
    "    # chrome_options.add_argument('--headless')  # Run browser in headless mode\n",
    "    chrome_options.add_argument('--disable-blink-features=AutomationControlled') # Bypass automation detection\n",
    "    chrome_options.add_argument(f'--user-agent={random.choice(user_agents)}')  # Randomize user-agent\n",
    "    chrome_options.add_argument('--start-maximized') # Open browser in maximized mode\n",
    "    chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration for stability\n",
    "    chrome_options.add_argument('--log-level=3')  # Suppress unnecessary logs\n",
    "    chrome_options.add_argument('--ignore-certificate-errors')  # Ignore SSL errors\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])  # Disable automation flags\n",
    "    \n",
    "    chrome_service = Service(executable_path=\"C:/Users/parni/OneDrive/Desktop/web_scraping_projects/yelp_scraping/drivers/chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(service=chrome_service, options=chrome_options) # Initialize WebDriver with options\n",
    "    return driver   # Return the configured WebDriver instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üü° Function: Save & Load Cookies\n",
    "# ============================\n",
    "def save_cookies(driver, filename=\"cookies.json\"):\n",
    "    \"\"\" Saves cookies to a JSON file. \"\"\"\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(driver.get_cookies(), file)\n",
    "    print(\"‚úÖ Cookies saved.\")\n",
    "\n",
    "def load_cookies(driver, filename=\"cookies.json\"):\n",
    "    \"\"\" Loads cookies from a JSON file. \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"r\") as file:\n",
    "            cookies = json.load(file)\n",
    "            for cookie in cookies:\n",
    "                driver.add_cookie(cookie)\n",
    "        print(\"‚úÖ Cookies loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ö†Ô∏è No cookies found. Proceeding without loading cookies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üü° Function: Scroll Down Page\n",
    "# ============================\n",
    "def scroll_down(driver, scroll_times=3, delay=1):\n",
    "    \"\"\" Scrolls down dynamically based on page height. \"\"\"\n",
    "    for _ in range(scroll_times):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üü° Function: Extract Yelp Business Data from Search Results\n",
    "# ============================\n",
    "def extract_businesses_from_page(driver):\n",
    "    \"\"\"\n",
    "    Extracts business names, ratings, and URLs from the current Yelp search results page.\n",
    "    \"\"\"\n",
    "    business_data = []  # Initialize an empty list to store business data\n",
    "    try:\n",
    "        # Locate all business items on the page\n",
    "        businesses = driver.find_elements(By.XPATH, '//div[contains(@class, \"container__09f24__FeTO6 y-css-1txhg36\")]')\n",
    "        for business in businesses:  # Iterate through each business element\n",
    "            try:\n",
    "                # Extract business name, rating, and URL\n",
    "                name_element = business.find_element(By.XPATH, './/h3')\n",
    "                rating_element = business.find_element(By.XPATH, './/div[@class=\"y-css-dnttlc\" and @aria-label]')\n",
    "                link_element = business.find_element(By.XPATH, './/a[contains(@class, \"y-css-1x1e1r2\")]')\n",
    "                \n",
    "                name = name_element.text.strip() if name_element else \"N/A\"   # Get business name text\n",
    "                rating = rating_element.get_attribute(\"aria-label\") if rating_element else \"N/A\"   # Get rating text\n",
    "                url = link_element.get_attribute('href') if link_element else \"N/A\"   # Get business URL\n",
    "                \n",
    "                business_data.append({\"Name\": name, \"Rating\": rating, \"URL\": url})  # Store extracted data\n",
    "                print(f\"üè¢ Extracted: {name} | {rating}\")  # Print extracted business info\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error extracting business data: {e}\")  # Handle extraction errors\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting businesses from page: {e}\")  # Handle overall extraction errors\n",
    "    return business_data  # Return extracted business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üü° Function: Extract All Businesses Dynamically from Multiple Pages\n",
    "# ============================\n",
    "def extract_all_businesses(driver, search_term, location, max_pages=3):\n",
    "    \"\"\"\n",
    "    Extracts business data across multiple pages with dynamic pagination.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for page in range(1, max_pages + 1):\n",
    "        start_value = (page - 1) * 10 + 1\n",
    "        url = f\"https://www.yelp.co.uk/search?find_desc={search_term}&find_loc={location}&start={start_value}\"\n",
    "        \n",
    "        print(f\"üìÑ Scraping page {page} with start={start_value}...\")  \n",
    "        driver.get(url)\n",
    "        \n",
    "        businesses = extract_businesses_from_page(driver)\n",
    "        print(f\"üîç Found {len(businesses)} businesses on page {page}\")\n",
    "        \n",
    "        if not businesses:\n",
    "            print(\"‚ö†Ô∏è No businesses found, stopping extraction.\")\n",
    "            break\n",
    "        \n",
    "        all_data.extend(businesses)\n",
    "        scroll_down(driver, scroll_times=3, delay=2)\n",
    "\n",
    "    print(f\"‚úÖ Extracted {len(all_data)} businesses in total.\")\n",
    "    return all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# üü° Function: Get Search Term from URL\n",
    "# ============================\n",
    "\n",
    "def get_search_term_from_url(url):\n",
    "    \"\"\"\n",
    "    Extracts the search term from the Yelp search URL.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    search_term = query_params.get('find_desc', [''])[0]  # Extract 'find_desc' parameter\n",
    "    return search_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üü° Function: Extract Location from URL\n",
    "# ============================\n",
    "def get_location_from_url(url):\n",
    "    \"\"\"\n",
    "    Extracts the location from the Yelp search URL.\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "    location = query_params.get('find_loc', [''])[0]  # Extract 'find_loc' parameter\n",
    "    return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üü° Main Function\n",
    "# ============================\n",
    "def main():\n",
    "    \"\"\" Main function to scrape Yelp data. \"\"\"\n",
    "    driver = setup_driver()\n",
    "    driver.get(\"https://www.yelp.com/\")\n",
    "    \n",
    "    input(\"üîπ Perform a search on Yelp and press Enter when ready...\")\n",
    "    \n",
    "    current_url = driver.current_url\n",
    "    search_term = get_search_term_from_url(current_url)\n",
    "    location = get_location_from_url(current_url)  # Automatically extract location from the URL\n",
    "    \n",
    "    print(f\"üîç Extracted search term: {search_term} | Location: {location}\")\n",
    "    \n",
    "    if not search_term or not location:\n",
    "        print(\"‚ö†Ô∏è Missing search term or location. Exiting.\")\n",
    "        driver.quit()\n",
    "        return\n",
    "    \n",
    "    all_businesses = extract_all_businesses(driver, search_term, location, max_pages=3)\n",
    "    \n",
    "    # Save data to DataFrame and CSV\n",
    "    df = pd.DataFrame(all_businesses)\n",
    "    df.to_csv(\"yelp_businesses.csv\", index=False)\n",
    "    \n",
    "    driver.quit()\n",
    "    print(all_businesses)\n",
    "    print(\"‚úÖ Scraping completed. Data saved to yelp_businesses.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extracted search term: Restauranter | Location: Oslo\n",
      "üìÑ Scraping page 1 with start=1...\n",
      "üè¢ Extracted: 2. Skandinavia | 4.7 star rating\n",
      "üè¢ Extracted: 3. The Salmon | 4.8 star rating\n",
      "üè¢ Extracted: 4. Elias Mat & S√•nt | 4.4 star rating\n",
      "üè¢ Extracted: 5. Oslo Street Food | 4.2 star rating\n",
      "üè¢ Extracted: 6. Way Down South | 4.4 star rating\n",
      "üè¢ Extracted: 7. Habsak | 4.2 star rating\n",
      "üè¢ Extracted: 8. Stangeriet | 4.9 star rating\n",
      "üè¢ Extracted: 9. Mathallen Oslo | 4.2 star rating\n",
      "üè¢ Extracted: 10. Vulkanfisk Sj√∏matbar | 4.4 star rating\n",
      "üè¢ Extracted: 11. Gamle Raadhus Restaurant | 4.4 star rating\n",
      "üîç Found 10 businesses on page 1\n",
      "üìÑ Scraping page 2 with start=11...\n",
      "üè¢ Extracted: 12. Taverna‚Äôn | 4.2 star rating\n",
      "üè¢ Extracted: 13. Lucky Bird | 3.9 star rating\n",
      "üè¢ Extracted: 14. Engebret Caf√© | 4.2 star rating\n",
      "üè¢ Extracted: 15. Fiskeriet | 4.2 star rating\n",
      "üè¢ Extracted: 16. Izakaya | 4.4 star rating\n",
      "üè¢ Extracted: 17. Istanbul | 4.1 star rating\n",
      "üè¢ Extracted: 18. Den Glade Italiener | 5 star rating\n",
      "üè¢ Extracted: 19. Smalhans | 3.9 star rating\n",
      "üè¢ Extracted: 20. Katla | 4.6 star rating\n",
      "üè¢ Extracted: 21. Brasserie Paleo | 4.4 star rating\n",
      "üîç Found 10 businesses on page 2\n",
      "üìÑ Scraping page 3 with start=21...\n",
      "üè¢ Extracted: 22. Gunnars Generasjonsbar | 4.6 star rating\n",
      "üè¢ Extracted: 23. Solsiden | 3.9 star rating\n",
      "üè¢ Extracted: 24. Sapporo Ramenbar | 4.2 star rating\n",
      "üè¢ Extracted: 25. La Sangria | 4.3 star rating\n",
      "üè¢ Extracted: 26. Lofoten Fiskerestaurant | 3.9 star rating\n",
      "üè¢ Extracted: 27. Einer | 5 star rating\n",
      "üè¢ Extracted: 28. Adriatic Cafe + | 4.8 star rating\n",
      "üè¢ Extracted: 29. Rorbua | 4.1 star rating\n",
      "üè¢ Extracted: 30. Tim Wendelboe | 4.6 star rating\n",
      "üè¢ Extracted: 31. Frognerseteren | 4.3 star rating\n",
      "üîç Found 10 businesses on page 3\n",
      "‚úÖ Extracted 30 businesses in total.\n",
      "[{'Name': '2. Skandinavia', 'Rating': '4.7 star rating', 'URL': 'https://www.yelp.co.uk/biz/skandinavia-oslo?osq=Restauranter'}, {'Name': '3. The Salmon', 'Rating': '4.8 star rating', 'URL': 'https://www.yelp.co.uk/biz/the-salmon-oslo?osq=Restauranter'}, {'Name': '4. Elias Mat & S√•nt', 'Rating': '4.4 star rating', 'URL': 'https://www.yelp.co.uk/biz/elias-mat-og-s%C3%A5nt-oslo?osq=Restauranter'}, {'Name': '5. Oslo Street Food', 'Rating': '4.2 star rating', 'URL': 'https://www.yelp.co.uk/biz/oslo-street-food-oslo?osq=Restauranter'}, {'Name': '6. Way Down South', 'Rating': '4.4 star rating', 'URL': 'https://www.yelp.co.uk/biz/way-down-south-oslo?osq=Restauranter'}, {'Name': '7. Habsak', 'Rating': '4.2 star rating', 'URL': 'https://www.yelp.co.uk/biz/habsak-oslo?osq=Restauranter'}, {'Name': '8. Stangeriet', 'Rating': '4.9 star rating', 'URL': 'https://www.yelp.co.uk/biz/stangeriet-oslo?osq=Restauranter'}, {'Name': '9. Mathallen Oslo', 'Rating': '4.2 star rating', 'URL': 'https://www.yelp.co.uk/biz/mathallen-oslo-oslo-2?osq=Restauranter'}, {'Name': '10. Vulkanfisk Sj√∏matbar', 'Rating': '4.4 star rating', 'URL': 'https://www.yelp.co.uk/biz/vulkanfisk-sj%C3%B8matbar-oslo?osq=Restauranter'}, {'Name': '11. Gamle Raadhus Restaurant', 'Rating': '4.4 star rating', 'URL': 'https://www.yelp.co.uk/biz/gamle-raadhus-restaurant-oslo?osq=Restauranter'}, {'Name': '12. Taverna‚Äôn', 'Rating': '4.2 star rating', 'URL': 'https://www.yelp.co.uk/biz/tavernan-oslo?osq=Restauranter'}, {'Name': '13. Lucky Bird', 'Rating': '3.9 star rating', 'URL': 'https://www.yelp.co.uk/biz/lucky-bird-oslo?osq=Restauranter'}, {'Name': '14. Engebret Caf√©', 'Rating': '4.2 star rating', 'URL': 'https://www.yelp.co.uk/biz/engebret-caf%C3%A9-oslo-2?osq=Restauranter'}, {'Name': '15. Fiskeriet', 'Rating': '4.2 star rating', 'URL': 'https://www.yelp.co.uk/biz/fiskeriet-oslo?osq=Restauranter'}, {'Name': '16. Izakaya', 'Rating': '4.4 star rating', 'URL': 'https://www.yelp.co.uk/biz/izakaya-oslo?osq=Restauranter'}, {'Name': '17. Istanbul', 'Rating': '4.1 star rating', 'URL': 'https://www.yelp.co.uk/biz/istanbul-oslo?osq=Restauranter'}, {'Name': '18. Den Glade Italiener', 'Rating': '5 star rating', 'URL': 'https://www.yelp.co.uk/biz/den-glade-italiener-oslo?osq=Restauranter'}, {'Name': '19. Smalhans', 'Rating': '3.9 star rating', 'URL': 'https://www.yelp.co.uk/biz/smalhans-oslo?osq=Restauranter'}, {'Name': '20. Katla', 'Rating': '4.6 star rating', 'URL': 'https://www.yelp.co.uk/biz/katla-oslo?osq=Restauranter'}, {'Name': '21. Brasserie Paleo', 'Rating': '4.4 star rating', 'URL': 'https://www.yelp.co.uk/biz/brasserie-paleo-oslo?osq=Restauranter'}, {'Name': '22. Gunnars Generasjonsbar', 'Rating': '4.6 star rating', 'URL': 'https://www.yelp.co.uk/biz/gunnars-generasjonsbar-oslo?osq=Restauranter'}, {'Name': '23. Solsiden', 'Rating': '3.9 star rating', 'URL': 'https://www.yelp.co.uk/biz/solsiden-oslo?osq=Restauranter'}, {'Name': '24. Sapporo Ramenbar', 'Rating': '4.2 star rating', 'URL': 'https://www.yelp.co.uk/biz/sapporo-ramenbar-oslo?osq=Restauranter'}, {'Name': '25. La Sangria', 'Rating': '4.3 star rating', 'URL': 'https://www.yelp.co.uk/biz/la-sangria-oslo?osq=Restauranter'}, {'Name': '26. Lofoten Fiskerestaurant', 'Rating': '3.9 star rating', 'URL': 'https://www.yelp.co.uk/biz/lofoten-fiskerestaurant-oslo?osq=Restauranter'}, {'Name': '27. Einer', 'Rating': '5 star rating', 'URL': 'https://www.yelp.co.uk/biz/einer-oslo?osq=Restauranter'}, {'Name': '28. Adriatic Cafe +', 'Rating': '4.8 star rating', 'URL': 'https://www.yelp.co.uk/biz/adriatic-cafe-oslo?osq=Restauranter'}, {'Name': '29. Rorbua', 'Rating': '4.1 star rating', 'URL': 'https://www.yelp.co.uk/biz/rorbua-oslo?osq=Restauranter'}, {'Name': '30. Tim Wendelboe', 'Rating': '4.6 star rating', 'URL': 'https://www.yelp.co.uk/biz/tim-wendelboe-oslo?osq=Restauranter'}, {'Name': '31. Frognerseteren', 'Rating': '4.3 star rating', 'URL': 'https://www.yelp.co.uk/biz/frognerseteren-oslo-2?osq=Restauranter'}]\n",
      "‚úÖ Scraping completed. Data saved to yelp_businesses.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# üöÄ Execute Main Function\n",
    "# ============================\n",
    "\n",
    "nest_asyncio.apply()  # Allow nested async loops\n",
    "# Run the main function \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
